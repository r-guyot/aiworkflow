<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Enable R users to leverage AI frameworks like Ollama and Llama.cpp • aiworkflow</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Enable R users to leverage AI frameworks like Ollama and Llama.cpp">
<meta name="description" content="ai_workflow is a R package that makes it easy to run typical AI-powered (mostly LLM-related) tasks with R. Its main focus is on Local AI support, while it can be expanded to third-party LLMs in the future.">
<meta property="og:description" content="ai_workflow is a R package that makes it easy to run typical AI-powered (mostly LLM-related) tasks with R. Its main focus is on Local AI support, while it can be expanded to third-party LLMs in the future.">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">aiworkflow</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.3.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="articles/first_steps.html">First Steps with aiworkflow</a></li>
    <li><a class="dropdown-item" href="articles/processing_skills.html">Processing Skills</a></li>
    <li><a class="dropdown-item" href="articles/saving_workflows.html">Saving workflows</a></li>
    <li><a class="dropdown-item" href="articles/tool_calling.html">Tool Calling</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="aiworkflow-package-for-r">AIworkflow Package for R<a class="anchor" aria-label="anchor" href="#aiworkflow-package-for-r"></a>
</h1></div>
<p>This package, <strong>aiworkflow</strong>, is aimed at making it simple to interact with local LLMs when using R. This package is NOT aimed at creating chat clients (while it could definitely support such a use case) but rather executing LLMs over a large amount of data, in a reproducible way. Think about executing LLMs NLP tasks on dataframes as a typical use case.</p>
<p>This package is very much in <em>alpha</em> stages. It can already do a lot of things, but it lacks complete testing coverage, and the API of the package is subject to change. You should be aware that functions may change and be deprecated until the 1.0 version is reached.</p>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>You can use install the github version directly with devtools:</p>
<pre><code><span><span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"r-guyot/aiworkflow"</span><span class="op">)</span></span></code></pre>
<p>or pak:</p>
<pre><code><span><span class="fu">pak</span><span class="fu">::</span><span class="fu"><a href="https://pak.r-lib.org/reference/pkg_install.html" class="external-link">pkg_install</a></span><span class="op">(</span><span class="st">"r-guyot/aiworkflow"</span><span class="op">)</span></span></code></pre>
<p>There is currently no CRAN package but this may change in the near future.</p>
</div>
<div class="section level2">
<h2 id="license">License<a class="anchor" aria-label="anchor" href="#license"></a>
</h2>
<p>LGPL v3, which means, in layman terms:</p>
<ul>
<li>you have to share and redistribute any modification you make to this package</li>
<li>you are free to use this package as-is to power your own applications, whether they are Open-source or proprietary. You do not have to release the code of your proprietary apps that use this package.</li>
</ul>
<p>Please refer to the full details of the LICENSE document in any case.</p>
</div>
<div class="section level2">
<h2 id="requirements">Requirements<a class="anchor" aria-label="anchor" href="#requirements"></a>
</h2>
<p>You need to have at least:</p>
<ul>
<li>an Ollama instance running on your machine, along with an embedding model and a LLM already downloaded on it.</li>
</ul>
<p>to be able to use this package at the moment. A qdrant instance is optional.</p>
</div>
<div class="section level2">
<h2 id="current-features">Current Features<a class="anchor" aria-label="anchor" href="#current-features"></a>
</h2>
<p>In its current version it brings the following features:</p>
<ul>
<li>pipes support for LLM operations</li>
<li>client for Ollama to run local LLM operations</li>
<li>client for Qdrant database to store vector embeddings</li>
<li>support for vision models (moondream, llava:v1.6, minicpm tested and working) through Ollama</li>
<li>support for basic RAG</li>
<li>support for tool calling for LLMs that support it (like Llama3.1)</li>
<li>support for local vector embeddings database using a feather file</li>
<li>numerous processing skills (pre-defined prompts) that can be used out of the box</li>
<li>support for chaining multiple LLM operations in pipes</li>
<li>support for numerous prompt modification functions (audience, role, style, etc…)</li>
<li>support for JSON output extraction</li>
<li>and probably some more…</li>
</ul>
</div>
<div class="section level2">
<h2 id="upcoming-features">Upcoming Features<a class="anchor" aria-label="anchor" href="#upcoming-features"></a>
</h2>
<div class="section level3">
<h3 id="cran">CRAN<a class="anchor" aria-label="anchor" href="#cran"></a>
</h3>
<p>The goal is to have this published on CRAN once this is robust enough and in a more complete shape.</p>
</div>
<div class="section level3">
<h3 id="llm-backend-support">LLM Backend support<a class="anchor" aria-label="anchor" href="#llm-backend-support"></a>
</h3>
<p>Ultimately the idea of this package is to expand to more backends to run LLMs:</p>
<ul>
<li>llama.cpp</li>
<li>VLLM</li>
<li>llamafile</li>
</ul>
</div>
<div class="section level3">
<h3 id="image-generation-support">Image Generation Support<a class="anchor" aria-label="anchor" href="#image-generation-support"></a>
</h3>
<p>This package will eventually also support image generation through the ComfyUI API (most likely).</p>
</div>
</div>
<div class="section level2">
<h2 id="contributions">Contributions<a class="anchor" aria-label="anchor" href="#contributions"></a>
</h2>
<p>If you are interested to contribute to this package, you are welcome to issue a PR. Please also consider filing requests for new features and of course bug reports.</p>
</div>
</div>
  </main><aside class="col-md-3"><div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small>LGPL (&gt;= 3)</small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing aiworkflow</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Raphael Guyot <br><small class="roles"> Author, maintainer </small>  </li>
</ul>
</div>



  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Raphael Guyot.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.9000.</p>
</div>

    </footer>
</div>





  </body>
</html>
