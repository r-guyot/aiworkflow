<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>First Steps with aiworkflow • aiworkflow</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="First Steps with aiworkflow">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">aiworkflow</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.2.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/first_steps.html">First Steps with aiworkflow</a></li>
    <li><a class="dropdown-item" href="../articles/processing_skills.html">Processing Skills</a></li>
    <li><a class="dropdown-item" href="../articles/saving_workflows.html">Saving workflows</a></li>
    <li><a class="dropdown-item" href="../articles/tool_calling.html">Tool Calling</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>First Steps with aiworkflow</h1>
            
      

      <div class="d-none name"><code>first_steps.Rmd</code></div>
    </div>

    
    
<p>Load the package at first.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-guyot.github.io/aiworkflow/">aiworkflow</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="setting-up-your-ollama-connection">Setting up your Ollama connection<a class="anchor" aria-label="anchor" href="#setting-up-your-ollama-connection"></a>
</h2>
<p>Ensure that you have a running <a href="https://ollama.com/download" class="external-link">Ollama instance</a> on your local
machine or somewhere available in your network. Installing Ollama is
very easy and works on multiple platforms. Ollama will work even on
machines equipped only with CPUs, while having machines with GPUs
(especially Nvidia) will make processing much faster. Once you have
Ollama installed you need to <a href="https://ollama.com/library" class="external-link">download at least one model</a> to get
started.</p>
<p>You can establish a connection using the below function.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">conn</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_ollama_connection.html">get_ollama_connection</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>By default it will use localhost and the 11434 port. If you want to
use a different setup, you can change such parameters:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">conn</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_ollama_connection.html">get_ollama_connection</a></span><span class="op">(</span>ip_ad <span class="op">=</span> <span class="st">"127.0.0.1"</span>,port <span class="op">=</span> <span class="st">"3524"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="your-first-workflow">Your First Workflow<a class="anchor" aria-label="anchor" href="#your-first-workflow"></a>
</h2>
<p>This is one of the most simple workflows you can make. To create a
workflow, you need to start with the ai_workflow() container command,
and then pipe instructions to it. In the below example we specify that
we want to use the ollama connector, and that we will use the llama3.1
model.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">wflow_basic</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ai_workflow.html">ai_workflow</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_connector.html">set_connector</a></span><span class="op">(</span><span class="st">"ollama"</span><span class="op">)</span>  <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_model.html">set_model</a></span><span class="op">(</span>model_name<span class="op">=</span> <span class="st">"llama3.1:8b-instruct-q5_K_M"</span><span class="op">)</span> </span>
<span><span class="co">#&gt; → Default IP address has been set to 127.0.0.1.</span></span>
<span><span class="co">#&gt; → Default port has been set to 11434.</span></span></code></pre></div>
<p>When selecting the ollama connector, it will use the default
connection parameters. You can however set arbitrary IP and port
parameters as described below, if you want to connect to an Ollama
instance that is living on a different machine.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">wflow_basic_on_different_machine</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ai_workflow.html">ai_workflow</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_connector.html">set_connector</a></span><span class="op">(</span><span class="st">"ollama"</span><span class="op">)</span>  <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_ip_addr.html">set_ip_addr</a></span><span class="op">(</span>ip_addr <span class="op">=</span> <span class="st">"192.168.1.12"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_port.html">set_port</a></span><span class="op">(</span>port <span class="op">=</span> <span class="fl">5256</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_model.html">set_model</a></span><span class="op">(</span>model_name<span class="op">=</span> <span class="st">"llama3.1:8b-instruct-q5_K_M"</span><span class="op">)</span> </span>
<span><span class="co">#&gt; → Default IP address has been set to 127.0.0.1.</span></span>
<span><span class="co">#&gt; → Default port has been set to 11434.</span></span>
<span><span class="co">#&gt; → IP address has been changed to 192.168.1.12.</span></span>
<span><span class="co">#&gt; → Port has been changed to 5256.</span></span></code></pre></div>
<p>At this stage your workflow exists, but does not do anything.</p>
<p>The next steps is to ask it to run some specific tasks. We can ask
with a simple prompt.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">wflow_basic</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/process_prompts.html">process_prompts</a></span><span class="op">(</span>prompts_vector <span class="op">=</span> <span class="st">"why is the sky blue? Answer with a short explanation"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/pull_final_answer.html">pull_final_answer</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; → Frequency Penalty was not specified and given a default value of 1.</span></span>
<span><span class="co">#&gt; → Presence Penalty was not specified and given a default value of 1.5.</span></span>
<span><span class="co">#&gt; → Repeat Penalty was not specified and given a default value of 1.2.</span></span>
<span><span class="co">#&gt; → Temperature was not specified and given a default value of 0.8.</span></span>
<span><span class="co">#&gt; → N_predict was not specified and given a default value of 200.</span></span>
<span><span class="co">#&gt; → Mode was not specified and 'chat' was selected by default.</span></span>
<span><span class="co">#&gt; → System Prompt was not specified and given a default value of 'You are a helpful AI assistant.'.</span></span>
<span><span class="co">#&gt; → Chat mode</span></span>
<span><span class="co">#&gt; The sky appears blue because of a phenomenon called scattering, where shorter (blue) wavelengths of light are scattered more than longer (red) wavelengths by tiny molecules of gases in the atmosphere. This scattering effect gives our sky its distinct blue color!</span></span></code></pre></div>
<p>By default the model answers with a list, so you want to use the
pull_final_answer() function to fetch the final textual answer from the
list.</p>
</div>
<div class="section level2">
<h2 id="customizing-output">Customizing Output<a class="anchor" aria-label="anchor" href="#customizing-output"></a>
</h2>
<p>You can now leverage more features from the package. Such as setting
the audience for your answers. Here we specify that the audience is 5
years old kids.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">wflow_eli5</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ai_workflow.html">ai_workflow</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_connector.html">set_connector</a></span><span class="op">(</span><span class="st">"ollama"</span><span class="op">)</span>  <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_model.html">set_model</a></span><span class="op">(</span>model_name<span class="op">=</span> <span class="st">"llama3.1:8b-instruct-q5_K_M"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_audience.html">set_audience</a></span><span class="op">(</span><span class="st">"Five years old kids"</span><span class="op">)</span></span>
<span><span class="co">#&gt; → Default IP address has been set to 127.0.0.1.</span></span>
<span><span class="co">#&gt; → Default port has been set to 11434.</span></span></code></pre></div>
<p>You can see how it changes the output. Don’t expect a great
explanation!</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">explanation_eli5</span> <span class="op">&lt;-</span> <span class="va">wflow_eli5</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/process_prompts.html">process_prompts</a></span><span class="op">(</span>prompts_vector <span class="op">=</span> <span class="st">"why is the sky blue? Answer with a short explanation"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/pull_final_answer.html">pull_final_answer</a></span><span class="op">(</span><span class="op">)</span> </span>
<span><span class="co">#&gt; → Frequency Penalty was not specified and given a default value of 1.</span></span>
<span><span class="co">#&gt; → Presence Penalty was not specified and given a default value of 1.5.</span></span>
<span><span class="co">#&gt; → Repeat Penalty was not specified and given a default value of 1.2.</span></span>
<span><span class="co">#&gt; → Temperature was not specified and given a default value of 0.8.</span></span>
<span><span class="co">#&gt; → N_predict was not specified and given a default value of 200.</span></span>
<span><span class="co">#&gt; → Mode was not specified and 'chat' was selected by default.</span></span>
<span><span class="co">#&gt; → System Prompt was not specified and given a default value of 'You are a helpful AI assistant.'.</span></span>
<span><span class="co">#&gt; → Chat mode</span></span></code></pre></div>
<p>This is the kind of explanation you get for the little kids out
there:</p>
<p>*“Let me tell you a SECRET about the SKY!</p>
<p>The sky looks BLUE because of something called LIGHT! When sunlight
comes from the sun, it’s like a big bunch of colorful rays shining
towards us.</p>
<p>And guess what happens when these light rays travel through our air
in the atmosphere? They get SCATTERED and start bouncing around
everywhere!</p>
<p>Blue is one of those colors that gets scattered more than any other
color. So when we look up at the sky, all those blue light rays bounce
back to our eyes, making it LOOK BLUE! Isn’t that COOL?!“*</p>
<p>Note that you can also change an existing workflow directly by piping
parameter setting into it. For example let’s modify the existing
workflow wflow_basic before calling the prompt:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">explanation_low_tech</span> <span class="op">&lt;-</span> <span class="va">wflow_basic</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="../reference/set_audience.html">set_audience</a></span><span class="op">(</span><span class="st">"people without scientific knowledge or background"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/process_prompts.html">process_prompts</a></span><span class="op">(</span>prompts_vector <span class="op">=</span> <span class="st">"why is the sky blue? Answer with a short explanation"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/pull_final_answer.html">pull_final_answer</a></span><span class="op">(</span><span class="op">)</span> </span>
<span><span class="co">#&gt; → Frequency Penalty was not specified and given a default value of 1.</span></span>
<span><span class="co">#&gt; → Presence Penalty was not specified and given a default value of 1.5.</span></span>
<span><span class="co">#&gt; → Repeat Penalty was not specified and given a default value of 1.2.</span></span>
<span><span class="co">#&gt; → Temperature was not specified and given a default value of 0.8.</span></span>
<span><span class="co">#&gt; → N_predict was not specified and given a default value of 200.</span></span>
<span><span class="co">#&gt; → Mode was not specified and 'chat' was selected by default.</span></span>
<span><span class="co">#&gt; → System Prompt was not specified and given a default value of 'You are a helpful AI assistant.'.</span></span>
<span><span class="co">#&gt; → Chat mode</span></span></code></pre></div>
<p>You should get something like that:</p>
<p>*“The sky appears blue because of something called light
scattering.</p>
<p>When sunlight enters our atmosphere, it’s made up of all different
colors like a big ol’ rainbow. But when these tiny particles in the air
(like dust and water vapor) bounce off those colorful lights, they
scatter shorter wavelengths more than longer ones. And guess what? Blue
is one of those short-wavelength colors!</p>
<p>So, as our eyes see this scattered light from every direction above
us, we perceive it as a big blue sky!“*</p>
<p>You can also set a specific tone or personality to answer a
question.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">wflow_snoop</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ai_workflow.html">ai_workflow</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_connector.html">set_connector</a></span><span class="op">(</span><span class="st">"ollama"</span><span class="op">)</span>  <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_model.html">set_model</a></span><span class="op">(</span>model_name<span class="op">=</span> <span class="st">"llama3.1:8b-instruct-q5_K_M"</span><span class="op">)</span><span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/set_style_of_voice.html">set_style_of_voice</a></span><span class="op">(</span><span class="st">"Snoop Dogg"</span><span class="op">)</span></span>
<span><span class="co">#&gt; → Default IP address has been set to 127.0.0.1.</span></span>
<span><span class="co">#&gt; → Default port has been set to 11434.</span></span>
<span></span>
<span><span class="va">snoop_answer</span> <span class="op">&lt;-</span> <span class="va">wflow_snoop</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/process_prompts.html">process_prompts</a></span><span class="op">(</span>prompts_vector <span class="op">=</span> <span class="st">"Explain how the stock exchange works in a short paragraph"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/pull_final_answer.html">pull_final_answer</a></span><span class="op">(</span><span class="op">)</span> </span>
<span><span class="co">#&gt; → Frequency Penalty was not specified and given a default value of 1.</span></span>
<span><span class="co">#&gt; → Presence Penalty was not specified and given a default value of 1.5.</span></span>
<span><span class="co">#&gt; → Repeat Penalty was not specified and given a default value of 1.2.</span></span>
<span><span class="co">#&gt; → Temperature was not specified and given a default value of 0.8.</span></span>
<span><span class="co">#&gt; → N_predict was not specified and given a default value of 200.</span></span>
<span><span class="co">#&gt; → Mode was not specified and 'chat' was selected by default.</span></span>
<span><span class="co">#&gt; → System Prompt was not specified and given a default value of 'You are a helpful AI assistant.'.</span></span>
<span><span class="co">#&gt; → Chat mode</span></span></code></pre></div>
<p>You should get something like that:</p>
<p><em>“Yo what’s good fam? Alright so you wanna know ‘bout da stock
exchangah, right? Okay lemme break it down for ya. See, it’s like one
big ol’ party where investors come to buy and sell shares of companies
they think is gonna be hot in the future. They put their money on these
stocks, kinda like bettin’ on a sports team or somethin’. If da company
does good, da stock price goes up and you make some dough! But if it
tanks… well, let’s just say you might wanna sit this one out, G. The
exchange is where all the buyin’ and sellin’ happens, kinda like an
online market but with real people makin’ deals face-to-face or over
phone calls. Word.”</em></p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Raphael Guyot.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.9000.</p>
</div>

    </footer>
</div>





  </body>
</html>
