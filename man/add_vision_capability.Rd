% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/workflows.R
\name{add_vision_capability}
\alias{add_vision_capability}
\title{Add vision capability to the workflow.}
\usage{
add_vision_capability(workflow_obj, max_image_dimension = NA)
}
\arguments{
\item{workflow_obj}{A workflow object containing all parameters describing the workflow required}

\item{max_image_dimension}{A numerical value (defaults to 672 if not provided) that defines the largest dimension (width or height) of the pictures to be sent to the model.}
}
\description{
\code{add_vision_capability} lets you declare that this model can support the description or extraction of information from images. Only few models support such capabilities.
}
\details{
Lets you declare that this workflow can leverage vision capabilities (i.e. you can also send images on top of the prompt, optionally).
Make sure that the model you include in your workflow has such vision capability in the first place.
It is usually limited to models like llava, moondream, and llama3.2-11b models (while there are probably more).
}
\examples{
myflow_test <- ai_workflow() |>
   set_connector("ollama")  |> 
   set_model(model_name= "llama3.1:8b-instruct-q5_K_M") |>
   set_n_predict(1000) |>
   set_temperature(0.8) |> 
   set_default_missing_parameters_in_workflow() |> 
   add_vision_capability()
   
}
